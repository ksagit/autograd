{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd import checkpoint\n",
    "from autograd.extend import primitive\n",
    "\n",
    "import numpy as onp\n",
    "from time import time\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from builtins import range, list as ag_list, tuple as ag_tuple\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "from autograd import grad\n",
    "from autograd.scipy.misc import logsumexp\n",
    "from os.path import dirname, join\n",
    "from autograd.misc.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rnn_params(input_size, state_size, output_size,\n",
    "                      param_scale=0.01, rs=npr.RandomState(0)):\n",
    "    return {'change': rs.randn(input_size + state_size + 1, state_size) * param_scale,\n",
    "            'predict': rs.randn(state_size + 1, output_size) * param_scale,\n",
    "            'init hiddens': rs.randn(1, state_size) * param_scale,}\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 0.5*(np.tanh(x) + 1.0)   # Output ranges from 0 to 1.\n",
    "\n",
    "def hiddens_to_output_probs(theta, hiddens):\n",
    "    output = concat_and_multiply(theta['predict'], hiddens)\n",
    "    return output - logsumexp(output, axis=1, keepdims=True)\n",
    "\n",
    "def concat_and_multiply(weights, *args):\n",
    "    cat_state = np.hstack(args + (np.ones((args[0].shape[0], 1)),))\n",
    "    return np.dot(cat_state, weights)\n",
    "\n",
    "input_size = 64\n",
    "state_size = 64\n",
    "output_size = 64\n",
    "\n",
    "batch_size = 64\n",
    "seq_len = 512\n",
    "num_checkpoints = 512\n",
    "\n",
    "theta = create_rnn_params(input_size, state_size, output_size)\n",
    "\n",
    "np.random.seed(0)\n",
    "inputs = [np.random.randn(batch_size, input_size) for _ in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autograd.differential_operators import binomial_checkpoint\n",
    "from autograd.builtins import list as ag_list, tuple as ag_tuple\n",
    "\n",
    "def rnn(theta, state, x):  \n",
    "    return np.tanh(concat_and_multiply(theta['change'], x, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_predict(params, inputs):\n",
    "    num_sequences = inputs[0].shape[0]\n",
    "    hidden_single = npr.RandomState(0).randn(1, state_size) * .01\n",
    "    hidden = np.repeat(hidden_single, num_sequences, axis=0)  \n",
    "    \n",
    "    outputs = [hiddens_to_output_probs(params, hidden)]\n",
    "    \n",
    "    for input in inputs:\n",
    "        hidden = rnn(params, hidden, input)\n",
    "        outputs.append(hiddens_to_output_probs(params, hidden))\n",
    "    return outputs\n",
    "\n",
    "loop = binomial_checkpoint(rnn, seq_len, num_checkpoints, hiddens_to_output_probs)\n",
    "\n",
    "def rnn_predict_checkpointed(params, inputs):\n",
    "    num_sequences = inputs[0].shape[0]\n",
    "    \n",
    "    hidden_single = npr.RandomState(0).randn(1, state_size) * .01\n",
    "    hidden = np.repeat(hidden_single, num_sequences, axis=0)\n",
    "    \n",
    "    return loop.fun(params, hidden, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7677478790283203\n"
     ]
    }
   ],
   "source": [
    "# change rnn_predict to rnn_predict_checkpointed and restart the notebook for comparison\n",
    "f = lambda theta: rnn_predict(theta, inputs)\n",
    "g = lambda theta: np.sum(sum(rnn_predict(theta, inputs)))\n",
    "\n",
    "# the first time grad is called introduces memory overhead, so we do it here and ignore it\n",
    "\n",
    "start = time()\n",
    "g1 = make_vjp(rnn_predict_checkpointed, 0)(theta, inputs)[0](output_grads)\n",
    "end = time()\n",
    "\n",
    "print(end - start)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4373729228973389"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_single = npr.RandomState(0).randn(1, state_size) * .01\n",
    "initial_state = np.repeat(hidden_single, batch_size, axis=0)\n",
    "\n",
    "output_grads = vspace(f(theta)).ones()\n",
    "\n",
    "start = time()\n",
    "g2 = vjp_general(theta, initial_state, inputs, output_grads, None, num_checkpoints, True)[0]\n",
    "end = time()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'change': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-8.62700490e-02,  1.25206451e-01,  9.03192207e-01, ...,\n",
       "          2.69645134e-01,  5.19298640e-01,  3.88437962e-01],\n",
       "        [-1.55154406e-02,  2.25149011e-02,  1.62348787e-01, ...,\n",
       "          4.84923640e-02,  9.33537326e-02,  6.98254223e-02],\n",
       "        [-6.77322536e+00,  9.83053247e+00,  7.09205017e+01, ...,\n",
       "          2.11706358e+01,  4.07753732e+01,  3.05005622e+01]]),\n",
       " 'init hiddens': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'predict': array([[-1.68798402e+00, -1.79298933e+00, -2.89756004e+00, ...,\n",
       "          3.71530123e-01, -1.33783387e+00,  1.55184686e+00],\n",
       "        [-6.67415463e+00, -7.06996178e+00, -1.14359396e+01, ...,\n",
       "          1.46839198e+00, -5.28430156e+00,  6.12600924e+00],\n",
       "        [-1.59802033e-01, -1.72135828e-01, -2.76878671e-01, ...,\n",
       "          3.52529863e-02, -1.27323708e-01,  1.48118928e-01],\n",
       "        ...,\n",
       "        [ 4.07539033e+00,  4.31875686e+00,  6.98484189e+00, ...,\n",
       "         -8.96695568e-01,  3.22719035e+00, -3.74150881e+00],\n",
       "        [ 7.31104792e-01,  7.79421231e-01,  1.25804146e+00, ...,\n",
       "         -1.61011077e-01,  5.80239142e-01, -6.73574951e-01],\n",
       "        [ 3.20157995e+02,  3.38793561e+02,  5.48203182e+02, ...,\n",
       "         -7.04276608e+01,  2.53389516e+02, -2.93684112e+02]])}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time:  0.5895800590515137\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "g1 = grad(g)(theta)\n",
    "end = time()\n",
    "\n",
    "print(\"elapsed time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.55160449204888\n",
      "-8.249401162174763e-12\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for key in g1:\n",
    "    print(np.sum(g1[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd.differential_operators import vspace, forward_loop_no_saving, checkpoint_policy, make_vjp\n",
    "\n",
    "function = rnn\n",
    "postprocess=lambda params, state: hiddens_to_output_probs(params, state)\n",
    "\n",
    "curried_function = lambda param_and_state, input: function(param_and_state[0], param_and_state[1], input)\n",
    "curried_function_vjp = make_vjp(curried_function, 0)\n",
    "\n",
    "curried_postprocess = lambda param_and_state: postprocess(param_and_state[0], param_and_state[1])\n",
    "curried_postprocess_vjp = make_vjp(curried_postprocess, 0)\n",
    "\n",
    "def vjp_one_checkpoint(parameters, state_0, inputs, postprocess_grads, state_grad_wrt_next_state, fst):\n",
    "    assert(len(inputs) > 0)\n",
    "    assert(len(postprocess_grads) > 0)\n",
    "    assert(len(inputs) + 1 == len(postprocess_grads))\n",
    "    \n",
    "    state_grad_vspace = vspace(state_0)\n",
    "    parameter_vspace = vspace(parameters)\n",
    "\n",
    "    parameter_grad = parameter_vspace.zeros()\n",
    "\n",
    "    if state_grad_wrt_next_state is None:\n",
    "        state_grad_wrt_next_state = state_grad_vspace.zeros()\n",
    "\n",
    "    for y in range(len(inputs) - 1, -1, -1):\n",
    "        state_y = forward_loop_no_saving(function, parameters, state_0, inputs[:y])\n",
    "        \n",
    "        state_vjp, state_yplusone = curried_function_vjp(ag_tuple((parameters, state_y)), inputs[y])\n",
    "        postprocess_vjp = curried_postprocess_vjp((parameters, state_yplusone))[0]\n",
    "        \n",
    "        parameter_grad_wrt_output, state_grad_wrt_output = postprocess_vjp(postprocess_grads[y + 1])\n",
    "        parameter_grad_wrt_next_state, state_grad_wrt_next_state = state_vjp(\n",
    "            state_grad_vspace.add(state_grad_wrt_output, state_grad_wrt_next_state)\n",
    "        )\n",
    "        \n",
    "        parameter_grad = parameter_vspace.add(parameter_grad, parameter_vspace.add(parameter_grad_wrt_output, parameter_grad_wrt_next_state))\n",
    "        \n",
    "    if fst:\n",
    "        postprocess_vjp = curried_postprocess_vjp((parameters, state_0))[0]\n",
    "        parameter_grad_wrt_output, state_grad_wrt_output = postprocess_vjp(postprocess_grads[0])\n",
    "        parameter_grad = parameter_vspace.add(parameter_grad, parameter_grad_wrt_output)\n",
    "        state_grad_wrt_next_state = state_grad_vspace.add(state_grad_wrt_output, state_grad_wrt_next_state)        \n",
    "    return parameter_grad, state_grad_wrt_next_state\n",
    "\n",
    "def vjp_general(parameters, state_0, inputs, postprocess_grads, state_grad_wrt_final_state, num_checkpoints, fst):\n",
    "    assert(len(inputs) > 0)\n",
    "    assert(len(postprocess_grads) > 0)\n",
    "    assert(len(inputs) + 1 == len(postprocess_grads))\n",
    "    \n",
    "    if num_checkpoints == 1 or len(inputs) == 1:\n",
    "        return vjp_one_checkpoint(parameters, state_0, inputs, postprocess_grads, state_grad_wrt_final_state, fst)\n",
    "    else:\n",
    "        print\n",
    "        \n",
    "        y = checkpoint_policy(len(inputs), num_checkpoints)\n",
    "        state_y = forward_loop_no_saving(function, parameters, state_0, inputs[:y])        \n",
    "        parameter_grad_wrt_case2, state_grad_wrt_case2 = vjp_general(\n",
    "            parameters, state_y, inputs[y:], postprocess_grads[y:], state_grad_wrt_final_state, num_checkpoints - 1, False\n",
    "        )        \n",
    "        parameter_grad_wrt_case1, state_grad_wrt_case1 = vjp_general(\n",
    "            parameters, state_0, inputs[:y], postprocess_grads[:y + 1], state_grad_wrt_case2, num_checkpoints, True and fst\n",
    "        )\n",
    "        return vspace(parameters).add(parameter_grad_wrt_case1, parameter_grad_wrt_case2), state_grad_wrt_case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
